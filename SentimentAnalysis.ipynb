{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Women's E-Commerce data\n",
    "In this project we apply methods from Sentiment Analysis on the dataset \"Women's E-Commerce Clothing Reviews\" (https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\n",
    "\n",
    "## Content of the Dataset\n",
    "\n",
    "This dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n",
    "\n",
    "- Clothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "- Age: Positive Integer variable of the reviewers age.\n",
    "- Title: String variable for the title of the review.\n",
    "- Review Text: String variable for the review body.\n",
    "- Rating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n",
    "- Recommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n",
    "- Positive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n",
    "- Division Name: Categorical name of the product high level division.\n",
    "- Department Name: Categorical name of the product department name.\n",
    "- Class Name: Categorical name of the product class name.\n",
    "\n",
    "## Approach\n",
    "The sentiment analysis of the clothing reviews is devided into the following 4 steps:\n",
    "1. Data pre-processing\n",
    "2. Build a lexicographic approach\n",
    "3. Build a supervised machine-learning model\n",
    "4. Evaluation and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/max/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/max/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP libraries and regular expressions\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Basic manipulation and numerics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK corpora and tools\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# function which does a train-test split for training a machine-learning model\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the data: \n",
      "['Clothing ID' 'Age' 'Title' 'Review Text' 'Rating' 'Recommended IND'\n",
      " 'Positive Feedback Count' 'Division Name' 'Department Name' 'Class Name'] \n"
     ]
    }
   ],
   "source": [
    "# read the data of 23486 Reviews of womens E-Commerce and 10 features\n",
    "data = pd.read_csv(\"data/WomensEcomm.csv\")\n",
    "data = data[data[\"Review Text\"].isna() == False] # remove samples without Review Text\n",
    "column_names = np.array(data.columns)[1:]\n",
    "\n",
    "# read in the dictionaries\n",
    "pos_words=open(\"data/positive_words.txt\",\"r\")\n",
    "pos_words=pos_words.read().split(\"\\n\")\n",
    "neg_words=open(\"data/negative_words.txt\",\"r\")\n",
    "neg_words=neg_words.read().split(\"\\n\")\n",
    "\n",
    "# Print the column names\n",
    "print(\"Columns of the data: \\n%s \" % column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first 5 columns of the data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing\n",
    "- Create a train-test split\n",
    "- Remove stopwords, punctuation and numbers and tokenize the sentences (done via process_sentence function)\n",
    "- Apply pre-processing on the whole data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data: Remove stop words, numbers and punctuation and tokenize the sentences\n",
    "train_data, test_data = train_test_split(data, test_size = 0.3)\n",
    "\n",
    "train_pos = train_data[ train_data[\"Recommended IND\"] == 1]\n",
    "train_neg = train_data[ train_data[\"Recommended IND\"] == 0]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_sentence(sample):\n",
    "    word_tokens = word_tokenize(sample) \n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "    filtered_sentence = [] \n",
    "\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words and len(w) > 3: \n",
    "            filtered_sentence.append(w)\n",
    "    \n",
    "    return filtered_sentence\n",
    "\n",
    "# Processed Review Texts (Train-Set)\n",
    "train_data_text = [process_sentence(sentence) for sentence in train_data[\"Review Text\"]]\n",
    "# Processed Review Texts (Negative reviews)\n",
    "train_data_neg = [process_sentence(sentence) for sentence in train_neg[\"Review Text\"]]\n",
    "# Processed Review Texts (Positive reviews)\n",
    "train_data_pos = [process_sentence(sentence) for sentence in train_pos[\"Review Text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some example how the output of the pre-processing looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: \n",
      "Recommend this vest - nice design - fabric is thicker than expected - might suggest a size smaller - plenty of room in loose styling \n",
      "\n",
      "Pre-processed sentence:\n",
      "['Recommend', 'vest', 'nice', 'design', 'fabric', 'thicker', 'expected', 'might', 'suggest', 'size', 'smaller', 'plenty', 'room', 'loose', 'styling']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original sentence: \\n%s \\n\" % train_data[\"Review Text\"].iloc[1])\n",
    "print(\"Pre-processed sentence:\\n%s\" % train_data_text[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lexicographic approach:\n",
    "Given a lexicon with words and their corresponding sentiments we count the number of negative and positive words.\n",
    "The lexicon originates from a Statistics for Social Data lecture of NYU and is available at: http://ptrckprry.com/course/ssd/. \n",
    "\n",
    "The following function: *get_sentiment_score* counts the number of positive and negative words in a given sentence given a list of positive words (*pos_words*) and negative words (*neg_words*). \n",
    "\n",
    "The prediction then is given by the ratio of positive over negative words. If there are more positive words then negative words we classify the sentence with a *1* (*positive sentiment*). If not it is *0* (*negative sentiment*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(sentence, ratio=0.5):\n",
    "    neg_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in pos_words:\n",
    "            pos_cnt += 1\n",
    "        elif word in neg_words:\n",
    "            neg_cnt += 1\n",
    "    if pos_cnt + neg_cnt > 0:\n",
    "        if pos_cnt / (pos_cnt + neg_cnt) > ratio:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Supervised Machine Learning Approach: Naive Bayes\n",
    "- Feature Extraction using word frequencies\n",
    "- classification using bayes theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting tupples of list of words and sentiment\n",
    "train_data_pos_df = pd.DataFrame({'Text':train_data_pos})\n",
    "train_data_pos_df['Sentiment'] = \"Positive\"\n",
    "train_data_neg_df = pd.DataFrame({'Text':train_data_neg})\n",
    "train_data_neg_df['Sentiment'] = \"Negative\"\n",
    "frames = [train_data_pos_df, train_data_neg_df]\n",
    "train_data_bayes = pd.concat(frames)\n",
    "\n",
    "train_data_bayes = tuple(zip(train_data_bayes.Text, train_data_bayes.Sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts all words to an array\n",
    "def get_words(train_data):\n",
    "    all = []\n",
    "    for (words, sentiment) in train_data:\n",
    "        all.extend(words)\n",
    "    return all\n",
    "\n",
    "# Measures frequency distribution\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    features = wordlist.keys()\n",
    "    return features\n",
    "\n",
    "w_features = get_word_features(get_words(train_data_bayes))\n",
    "\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in w_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Supervised Machine Learning Approach: Support Vector Machine\n",
    "- Feature Extraction using tf_idf\n",
    "- Classification using SVM with kernels: linear, polynomial, rbf and sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction with tf_idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# The SVM implementation\n",
    "from sklearn import svm\n",
    "# Metrics for easy model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# A vectorizer that can with tf_idf features on some data and transform the data accordingly\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "\n",
    "# Feature extraction on training- and testing data\n",
    "train_vectors = vectorizer.fit_transform(train_data['Review Text'])\n",
    "test_vectors = vectorizer.transform(test_data['Review Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Naive Bayes classifier\n",
    "training_set = nltk.classify.apply_features(extract_features, train_data_bayes)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "# Making predictions for the testing dataset\n",
    "predictions_bayes = [classifier.classify(extract_features(obj.split())) for obj in test_data[\"Review Text\"]]\n",
    "bin_pred_bayes = [1 if sentiment == \"Positive\" else 0 for sentiment in predictions_bayes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SVM with a linear kernel\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(train_vectors, train_data['Recommended IND'])\n",
    "prediction_linear = classifier_linear.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SVM with a polynomial kernel (degree of freedom is 3 by default)\n",
    "classifier_poly = svm.SVC(kernel='poly')\n",
    "classifier_poly.fit(train_vectors, train_data['Recommended IND'])\n",
    "prediction_poly = classifier_poly.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SVM with a rbf kernel\n",
    "classifier_rbf = svm.SVC(kernel='rbf')\n",
    "classifier_rbf.fit(train_vectors, train_data['Recommended IND'])\n",
    "prediction_rbf = classifier_rbf.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SVM with a sigmoid kernel\n",
    "classifier_sigm = svm.SVC(kernel='sigmoid')\n",
    "classifier_sigm.fit(train_vectors, train_data['Recommended IND'])\n",
    "prediction_sigm = classifier_sigm.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using the Lexicographic approach\n",
    "sentiments_40 = [get_sentiment_score(sentence, 0.4) for sentence in train_data_text]\n",
    "sentiments_50 = [get_sentiment_score(sentence, 0.5) for sentence in train_data_text]\n",
    "sentiments_60 = [get_sentiment_score(sentence, 0.6) for sentence in train_data_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reports for SVM\n",
    "report_svm_linear = classification_report(test_data['Recommended IND'], prediction_linear, output_dict=True)\n",
    "report_svm_poly = classification_report(test_data['Recommended IND'], prediction_poly, output_dict=True)\n",
    "report_svm_rbf = classification_report(test_data['Recommended IND'], prediction_rbf, output_dict=True)\n",
    "report_svm_sigm = classification_report(test_data['Recommended IND'], prediction_sigm, output_dict=True)\n",
    "\n",
    "# Report for Naive Bayes\n",
    "report_bayes = classification_report(test_data[\"Recommended IND\"], bin_pred_bayes, output_dict=True)\n",
    "\n",
    "# Reports for Lexicographic approach\n",
    "report_lex_40 = classification_report(train_data[\"Recommended IND\"], sentiments_40, output_dict=True)\n",
    "report_lex_50 = classification_report(train_data[\"Recommended IND\"], sentiments_50, output_dict=True)\n",
    "report_lex_60 = classification_report(train_data[\"Recommended IND\"], sentiments_60, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'linear' : report_svm_linear,\n",
    "           'poly' : report_svm_poly,\n",
    "           'rbf' : report_svm_rbf,\n",
    "           'sigm' : report_svm_sigm,\n",
    "           'bayes' : report_bayes,\n",
    "           'lex_40' : report_lex_40,\n",
    "           'lex_50' : report_lex_50,\n",
    "           'lex_60' : report_lex_60}\n",
    "\n",
    "def get_results(report):\n",
    "    return [str(round(report['0']['precision']*100, 2)) + \"%\",\n",
    "           str(round(report['0']['recall']*100, 2)) + \"%\",\n",
    "           str(round(report['1']['precision']*100, 2)) + \"%\",\n",
    "           str(round(report['1']['recall']*100, 2)) + \"%\",\n",
    "           str(round(report['accuracy']*100, 2)) + \"%\"]\n",
    "\n",
    "results_summary = pd.DataFrame([get_results(models[model]) for model in models.keys()],\n",
    "                               index=['SVM linear kernel', \n",
    "                                      'SVM polynomial kernel', \n",
    "                                      'SVM rbf kernel',\n",
    "                                     'SVM sigmoid kernel',\n",
    "                                     'Naive Bayes',\n",
    "                                     'Lexicographic ratio = 40%',\n",
    "                                     'Lexicographic ratio = 50%',\n",
    "                                     'Lexicographic ratio = 60%'],\n",
    "                               columns=['precision negative',\n",
    "                                                             'recall negative',\n",
    "                                                            'precision positive',\n",
    "                                                            'recall positive',\n",
    "                                                            'total accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary.to_csv('results', header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
